{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß™ Smart Waste Classifier Project\n",
    "\n",
    "This notebook guides you through building a basic AI model to classify waste into four categories: Plastic, Paper, Metal, and Organic. It includes data loading, model training, evaluation, and export steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Step 1: Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists: False\n",
      "Folders: Path not found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "data_dir = 'C:/Users/damia/Desktop/Sustainable Living Labs SL2/waste_dataset'\n",
    "print(\"Exists:\", os.path.exists(data_dir))\n",
    "print(\"Folders:\", os.listdir(data_dir) if os.path.exists(data_dir) else \"Path not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38 images belonging to 4 classes.\n",
      "Found 8 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# üìÇ Step 2: Load and Preprocess Dataset\n",
    "# Only accepts JPG and PNG images (no wepg and avif images)\n",
    "data_dir = 'C:/Users/damia/Desktop/SL2/waste_dataset'\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 16\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 82944)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               10616960  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,636,868\n",
      "Trainable params: 10,636,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# üß† Step 3: Build the Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Removing: C:/Users/damia/Desktop/SL2/waste_dataset\\metal\\desktop.ini (not a valid image)\n",
      "‚ùå Removing: C:/Users/damia/Desktop/SL2/waste_dataset\\organic\\desktop.ini (not a valid image)\n",
      "‚ùå Removing: C:/Users/damia/Desktop/SL2/waste_dataset\\paper\\desktop.ini (not a valid image)\n",
      "‚ùå Removing: C:/Users/damia/Desktop/SL2/waste_dataset\\plastic\\desktop.ini (not a valid image)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "dataset_dir = 'C:/Users/damia/Desktop/SL2/waste_dataset'\n",
    "\n",
    "for folder in os.listdir(dataset_dir):\n",
    "    folder_path = os.path.join(dataset_dir, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                img.verify()  # Check if it's a valid image\n",
    "        except Exception:\n",
    "            print(f\"‚ùå Removing: {file_path} (not a valid image)\")\n",
    "            os.remove(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30 imgs - What level of accuracy are you going for? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 444ms/step - loss: 5.2165 - accuracy: 0.2105 - val_loss: 8.9289 - val_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 350ms/step - loss: 6.0350 - accuracy: 0.2632 - val_loss: 2.0711 - val_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 309ms/step - loss: 1.3838 - accuracy: 0.3684 - val_loss: 1.3567 - val_accuracy: 0.3750\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 1.1369 - accuracy: 0.5789 - val_loss: 1.2853 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 354ms/step - loss: 0.6197 - accuracy: 0.8684 - val_loss: 1.1066 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.4380 - accuracy: 0.8421 - val_loss: 1.3312 - val_accuracy: 0.6250\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.3636 - accuracy: 0.8684 - val_loss: 1.4886 - val_accuracy: 0.6250\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 327ms/step - loss: 0.1472 - accuracy: 1.0000 - val_loss: 1.7735 - val_accuracy: 0.6250\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 331ms/step - loss: 0.0674 - accuracy: 0.9737 - val_loss: 2.0481 - val_accuracy: 0.6250\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 307ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 2.5288 - val_accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "# üîÅ Step 4: Train the Model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 344ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       2.0\n",
      "           1       0.00      0.00      0.00       2.0\n",
      "           2       0.00      0.00      0.00       2.0\n",
      "           3       0.00      0.00      0.00       2.0\n",
      "\n",
      "    accuracy                           0.00       8.0\n",
      "   macro avg       0.00      0.00      0.00       8.0\n",
      "weighted avg       0.00      0.00      0.00       8.0\n",
      "\n",
      "Confusion Matrix:\n",
      " [[0 1 0 1]\n",
      " [1 0 0 1]\n",
      " [1 1 0 0]\n",
      " [0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# üìä Step 5: Evaluate the Model\n",
    "val_data.reset()\n",
    "predictions = model.predict(val_data)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = val_data.classes\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ Step 6: Save the Model\n",
    "model.save('waste_classifier_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
